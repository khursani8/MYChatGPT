# MYChatGPT

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/tatsu-lab/stanford_alpaca/blob/main/LICENSE)
[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)](https://github.com/tatsu-lab/stanford_alpaca/blob/main/DATA_LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

This is the repo for MYChatGPT project based on Stanford [Alpaca](https://github.com/tatsu-lab/stanford_alpaca/), which aims to build and share an instruction-following LLM model. The repo contains:

- The [1K data](#data-release) used for fine-tuning the model.
- The code for [fine-tuning the model](#fine-tuning).

**Usage and License Notices**: MYChatGPT is intended and licensed for research use only. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.

## Overview

The current MYChatGPT model is fine-tuned from a 7B RWKV model on 1K instruction-following data generated by the techniques in the Self-Instruct [2] paper, with some modifications that we discuss in the next section.

MYChatGPT is still under development, and there are many limitations that have to be addressed.
Importantly, we have not yet fine-tuned the MYChatGPT model to be safe and harmless.
We thus encourage users to be cautious when interacting with MYChatGPT, and to report any concerning behavior to help improve the safety and ethical considerations of the model.

[`malay.json`](./malay.json) contains 1K instruction-following data we used for fine-tuning the Alpaca model.
This JSON file is a list of dictionaries, each dictionary contains the following fields:

- `instruction`: `str`, describes the task the model should perform. Each of the 1K instructions is unique.
- `input`: `str`, optional context or input for the task. For example, when the instruction is "Summarize the following article", the input is the article. Around 40% of the examples have an input.
- `output`: `str`, the answer to the instruction as generated by `text-davinci-003`.

We used the following prompts for fine-tuning the Alpaca model:

- for examples with a non-empty input field:

 ```
 Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.
 
 ### Instruction:
 {instruction}
 
 ### Input:
 {input}
 
 ### Response:
 ```

- for examples with an empty input field:

 ```
 Below is an instruction that describes a task. Write a response that appropriately completes the request.
 
 ### Instruction:
 {instruction}
 
 ### Response:
 ```

## Data Generation Process
For data generation process can refer to Stanford Alpaca repo


## Fine-tuning

We fine-tune our models using standard Hugging Face training code with the following hyperparameters:

| Hyperparameter | Value |
|----------------|-------|
| Batch size     | 128   |
| Learning rate  | 2e-5  |
| Epochs         | 3     |
| Max length     | 512   |
| Weight decay   | 0     |


To reproduce our fine-tuning runs for LLaMA, first install the requirements

```bash
pip install -r requirements.txt
```

# Contributors

<a href="#readme">
    <img alt="logo" width="30%" src="https://contributors-img.firebaseapp.com/image?repo=huseinzol05/malaya">
</a>

## What I can contribute:
1. Add more seed task in seed_task_ms.jsonl
2. Fix translated malay word from indonesian to malay in malay.json
3. Fix logic error or math error in malay.json

## What other possible issue with the dataset? https://github.com/gururise/AlpacaDataCleaned#issues-with-the-original-dataset
1. Hallucinations: Many instructions in the original dataset had instructions referencing data on the internet, which just caused GPT3 to hallucinate an answer.
2. Empty outputs: Some entries in the original dataset had empty outputs.
3. Empty code examples: Some descriptions in the original dataset were missing code examples, making it difficult to understand the intended behavior of the code.
4. Instructions to generate something it not capable of like generate image: Some descriptions in the original dataset included instructions to generate images, something obviously not possible.
5. N/A outputs: Some code snippets in the original dataset had N/A outputs.
6. Inconsistent input field: The original dataset had inconsistent usage of the input field when it was supposed to be empty.
```
"input":"<no input>"
"input":"No input"
"input":"noinput"
"input":"<noinput>"
```
7. Wrong answers: Some instructions/questions in the original dataset had incorrect answers. About 80% of the math problems are estimated to have incorrect answers.
8. Non-Sensical/Unclear instructions: Many instructions are unclear, we try to clarify (or re-write) if instructions are non-sensical. Instructions that are slightly unclear, but where one could deduce the meaning are not altered.
9. Extraneous escape and control characters: The original dataset had several entries with extraneous escape and control characters.


## How to edit the file?
press command in this repo page, if you read this text from github you already in this repo page
or
go to here github.dev

## What is seed task?
You can think of it list of instruction we want to train LLM model to reply
From that seed task we can do augmentation by asking openai model to create similar task and that is malay.json
We finetune malay.json to LLM to answer any malay related question.

## I don't want to run the model on my own, is there any online alternative?
Yup, you can try [Nous](https://amanz.my/2023385612/)
This repo mainly for research purpose might be change in future in case many people request to let it be open for commercial purpose
